{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtE6rcSzZJrz",
        "outputId": "5aab6d6c-0878-4837-c701-55aa63997042"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.8.13 ('dlav')' requires ipykernel package.\n",
            "Run the following command to install 'ipykernel' into the Python environment. \n",
            "Command: 'conda install -n dlav ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# If the notebook is used by itself, uncomment\n",
        "# !git clone https://github.com/HugoCasa/dlav-group1.git\n",
        "# %cd dlav-group1/m2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgKn9fFPaPKR",
        "outputId": "51a5719e-ab24-4c29-867f-65ddf72e62a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.11.1)\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.10)\n",
            "Requirement already satisfied: lap in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Collecting cython_bbox\n",
            "  Downloading cython_bbox-0.1.3.tar.gz (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 203 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.0.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.2.0)\n",
            "Building wheels for collected packages: cython-bbox\n",
            "  Building wheel for cython-bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cython-bbox: filename=cython_bbox-0.1.3-cp37-cp37m-linux_x86_64.whl size=58445 sha256=3b33998dbb23110f6425d7e68f03ac74831b07a6ae327efafa7fc11be0786a35\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/82/21/5def8bc98ae4ea436d7f0decb7194d20d7e3e6d0578a4129d7\n",
            "Successfully built cython-bbox\n",
            "Installing collected packages: cython-bbox\n",
            "Successfully installed cython-bbox-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxruntime mediapipe lap cython_bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Fj9YcAnsT4B_"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import io\n",
        "\n",
        "import copy\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "from helpers import *\n",
        "\n",
        "from Detector.detector import ObjectDetector\n",
        "from Tracker.tracker import MultiObjectTracker\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6pCmkJrUC9g"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u7wrAzsZIFh"
      },
      "source": [
        "## Helper Functions\n",
        "Below are a few helper converting between different image data types and formats and to create the webcam video stream using javascript. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "09b_0FAnUa9y"
      },
      "outputs": [],
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ghUlAJzKSjFT"
      },
      "outputs": [],
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth; 640\n",
        "      captureCanvas.height = 480; //video.videoHeight; 480\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_xcqQZKYzAj"
      },
      "source": [
        "## Resulting Milestone 2\n",
        "Below is the result of what we have done for Milestone 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fDM3ndrGZIFk",
        "outputId": "25888561-20fa-48ae-d861-e67103c523fd"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    var video;\n    var div = null;\n    var stream;\n    var captureCanvas;\n    var imgElement;\n    var labelElement;\n    \n    var pendingResolve = null;\n    var shutdown = false;\n    \n    function removeDom() {\n       stream.getVideoTracks()[0].stop();\n       video.remove();\n       div.remove();\n       video = null;\n       div = null;\n       stream = null;\n       imgElement = null;\n       captureCanvas = null;\n       labelElement = null;\n    }\n    \n    function onAnimationFrame() {\n      if (!shutdown) {\n        window.requestAnimationFrame(onAnimationFrame);\n      }\n      if (pendingResolve) {\n        var result = \"\";\n        if (!shutdown) {\n          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n        }\n        var lp = pendingResolve;\n        pendingResolve = null;\n        lp(result);\n      }\n    }\n    \n    async function createDom() {\n      if (div !== null) {\n        return stream;\n      }\n\n      div = document.createElement('div');\n      div.style.border = '2px solid black';\n      div.style.padding = '3px';\n      div.style.width = '100%';\n      div.style.maxWidth = '600px';\n      document.body.appendChild(div);\n      \n      const modelOut = document.createElement('div');\n      modelOut.innerHTML = \"<span>Status:</span>\";\n      labelElement = document.createElement('span');\n      labelElement.innerText = 'No data';\n      labelElement.style.fontWeight = 'bold';\n      modelOut.appendChild(labelElement);\n      div.appendChild(modelOut);\n           \n      video = document.createElement('video');\n      video.style.display = 'block';\n      video.width = div.clientWidth - 6;\n      video.setAttribute('playsinline', '');\n      video.onclick = () => { shutdown = true; };\n      stream = await navigator.mediaDevices.getUserMedia(\n          {video: { facingMode: \"environment\"}});\n      div.appendChild(video);\n\n      imgElement = document.createElement('img');\n      imgElement.style.position = 'absolute';\n      imgElement.style.zIndex = 1;\n      imgElement.onclick = () => { shutdown = true; };\n      div.appendChild(imgElement);\n      \n      const instruction = document.createElement('div');\n      instruction.innerHTML = \n          '<span style=\"color: red; font-weight: bold;\">' +\n          'When finished, click here or on the video to stop this demo</span>';\n      div.appendChild(instruction);\n      instruction.onclick = () => { shutdown = true; };\n      \n      video.srcObject = stream;\n      await video.play();\n\n      captureCanvas = document.createElement('canvas');\n      captureCanvas.width = 640; //video.videoWidth; 640\n      captureCanvas.height = 480; //video.videoHeight; 480\n      window.requestAnimationFrame(onAnimationFrame);\n      \n      return stream;\n    }\n    async function stream_frame(label, imgData) {\n      if (shutdown) {\n        removeDom();\n        shutdown = false;\n        return '';\n      }\n\n      var preCreate = Date.now();\n      stream = await createDom();\n      \n      var preShow = Date.now();\n      if (label != \"\") {\n        labelElement.innerHTML = label;\n      }\n            \n      if (imgData != \"\") {\n        var videoRect = video.getClientRects()[0];\n        imgElement.style.top = videoRect.top + \"px\";\n        imgElement.style.left = videoRect.left + \"px\";\n        imgElement.style.width = videoRect.width + \"px\";\n        imgElement.style.height = videoRect.height + \"px\";\n        imgElement.src = imgData;\n      }\n      \n      var preCapture = Date.now();\n      var result = await new Promise(function(resolve, reject) {\n        pendingResolve = resolve;\n      });\n      shutdown = false;\n      \n      return {'create': preShow - preCreate, \n              'show': preCapture - preShow, \n              'capture': Date.now() - preCapture,\n              'img': result};\n    }\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "USE_GPU = False\n",
        "CAP_FPS = 20\n",
        "TARGET_GESTURE_ID = 2\n",
        "INIT_TIME_SEC = 10\n",
        "IOU_THRESHOLD_SIMILAR_BBOX = 0.5\n",
        "\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "\n",
        "# Hand Gesture Detection\n",
        "gesture_detector = ObjectDetector(\n",
        "    name= \"hand_gesture\",\n",
        "    target_id= None,\n",
        "    use_gpu=USE_GPU\n",
        ")\n",
        "\n",
        "# People Detection\n",
        "people_detector = ObjectDetector(\n",
        "    name= \"yolox\",\n",
        "    target_id = 1, # Detect people only\n",
        "    use_gpu=USE_GPU,\n",
        ")\n",
        "\n",
        "# Person Re-identification\n",
        "tracker = MultiObjectTracker(\n",
        "    \"bytetrack\",\n",
        "    CAP_FPS,\n",
        "    use_gpu=USE_GPU,\n",
        ")\n",
        "\n",
        "# Person Re-identification\n",
        "person_reid = MultiObjectTracker(\n",
        "    \"person_reid\",\n",
        "    CAP_FPS,\n",
        "    use_gpu=USE_GPU,\n",
        ")\n",
        "\n",
        "t_target_id = None\n",
        "pr_target_id = None\n",
        "first_detection_time = None\n",
        "target_bbox = []\n",
        "\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    debug_image = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # Person  Detection\n",
        "    d_bboxes, d_scores, d_class_ids = people_detector(frame)\n",
        "\n",
        "\n",
        "    # Multi People Tracking\n",
        "    track_ids, t_bboxes, t_scores, t_class_ids = tracker(\n",
        "        frame,\n",
        "        d_bboxes,\n",
        "        d_scores,\n",
        "        d_class_ids,\n",
        "    )\n",
        "\n",
        "    if t_target_id == None:\n",
        "        # Hand Gesture Detection\n",
        "        hg_bboxes, hg_scores, hg_class_ids = gesture_detector(frame)\n",
        "\n",
        "        # Draw gesture detection\n",
        "        draw_debug_info_detector(debug_image, hg_bboxes, hg_scores, hg_class_ids)\n",
        "\n",
        "        # If at least two target gesture detected\n",
        "        if  hg_class_ids.count(TARGET_GESTURE_ID) > 1:\n",
        "            \n",
        "            # Compute center coords of target gestures\n",
        "            hand_centers = []\n",
        "            for hg_box, hg_id in zip(hg_bboxes, hg_class_ids):\n",
        "                if hg_id == TARGET_GESTURE_ID:\n",
        "                    hand_centers.append(calc_center(hg_box))\n",
        "\n",
        "            # For each detected people count number of detected gesture in their box  \n",
        "            for t_box, t_id in zip(t_bboxes, track_ids):\n",
        "                count_gesture_in_box = 0\n",
        "                for hand_center in hand_centers:\n",
        "                    if in_bounding_box(hand_center, t_box):\n",
        "                        count_gesture_in_box+=1\n",
        "                # If more than one, set it as target people\n",
        "                if count_gesture_in_box > 1:\n",
        "                    t_target_id = t_id\n",
        "                    first_detection_time = time.time()\n",
        "    else:\n",
        "        target_bbox = retrieve_target_bbox(t_target_id, track_ids, t_bboxes)\n",
        "\n",
        "        target_detected_in_frame = len(target_bbox) != 0\n",
        "\n",
        "        # INIT_TIME_SEC of init for reid or target person not detected in frame by tracker\n",
        "        if (first_detection_time != None and time.time() - first_detection_time <= INIT_TIME_SEC) or (not target_detected_in_frame):\n",
        "            \n",
        "            pr_track_ids, pr_bboxes, pr_scores, pr_class_ids = person_reid(\n",
        "                frame,\n",
        "                d_bboxes,\n",
        "                d_scores,\n",
        "                d_class_ids,\n",
        "            )\n",
        "\n",
        "\n",
        "            if pr_target_id == None and len(pr_bboxes) > 0:\n",
        "\n",
        "                # Ow this one\n",
        "                best_matching_idx, IOU_score = compute_best_matching_bbox_idx(target_bbox, pr_bboxes)\n",
        "                if (IOU_score > IOU_THRESHOLD_SIMILAR_BBOX):\n",
        "                    pr_target_id = pr_track_ids[best_matching_idx]   \n",
        "\n",
        "            elif not target_detected_in_frame:\n",
        "                if pr_target_id in pr_track_ids and len(t_bboxes) > 0:\n",
        "\n",
        "                    # Ow this one\n",
        "                    best_matching_idx, IOU_score = compute_best_matching_bbox_idx(pr_bboxes[pr_track_ids.index(pr_target_id)], t_bboxes)\n",
        "                    if (IOU_score > IOU_THRESHOLD_SIMILAR_BBOX):\n",
        "                        t_target_id = track_ids[best_matching_idx]  \n",
        "\n",
        "\n",
        "            else:\n",
        "                draw_target_bbox(debug_image, target_bbox)\n",
        "    \n",
        "                    \n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    debug_image = draw_debug_info(\n",
        "        debug_image,\n",
        "        elapsed_time,\n",
        "        track_ids,\n",
        "        t_bboxes,\n",
        "        t_scores,\n",
        "        t_class_ids,\n",
        "        t_target_id,\n",
        "    )\n",
        "\n",
        "    debug_image[:,:,3] = (debug_image.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(debug_image)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e4NrNs4GTtW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Milestone 2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "424ff4cc6372ec50f3fee034d1f61a10bc9258d1a54962292be9f4c33963e588"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('dlav')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
